1)Підрахунок частот слів за допомогою HashMap: Використання хеш-таблиць (HashMap) дозволяє підраховувати частоту слів з лінійною складністю O(n), де n — кількість слів. Це значно швидше, ніж вкладені цикли з квадратичною складністю O(n^2).
2)Метод Files.readString: Заміна Files.readAllBytes на Files.readString для читання вмісту файлу. Це простіший і оптимізований спосіб отримати текст з файлу.
3)Перевірка на порожні слова: Додано перевірку на порожні слова в циклі підрахунку частоти, щоб уникнути внесення непотрібних записів у мапу.
4)Використання Map.merge: Замість getOrDefault у циклі підрахунку частоти використовується merge, що зменшує кількість рядків коду і підвищує читабельність.
5)Сортування: Використовується new ArrayList<>(frequencyMap.entrySet()) для створення списку, що дозволяє безпосередньо сортувати частоти.
6)Очищення тексту: Використання регулярних виразів для очищення тексту та перетворення його на нижній регістр — це ефективний спосіб нормалізації даних, який виконується лише один раз.
7)Підрахунок частоти слів "на льоту": Виконується під час читання, уникаючи зайвих операцій з масивами рядків.
8)Мінімізація конкатенації рядків: Оригінальний код використовував рядки для додавання слів у рядок, що кожного разу перезбирало об'єкт рядка. У новому варіанті всі операції працюють з колекціями (HashMap, List), що значно знижує навантаження на систему.
